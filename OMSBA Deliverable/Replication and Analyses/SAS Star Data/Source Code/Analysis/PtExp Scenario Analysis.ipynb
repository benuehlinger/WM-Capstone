{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNaudyZFsfMLqHjLnqmM1x7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vCiUJVNhJvrk","executionInfo":{"status":"ok","timestamp":1733021891941,"user_tz":300,"elapsed":22279,"user":{"displayName":"Ben Uehlinger","userId":"08830289083401511848"}},"outputId":"04c93c2c-d86d-48ab-a866-b791074025f7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xGXJM_fLGk7p","executionInfo":{"status":"ok","timestamp":1733022700103,"user_tz":300,"elapsed":7567,"user":{"displayName":"Ben Uehlinger","userId":"08830289083401511848"}},"outputId":"ec84aa2b-e483-4665-bcf2-7254bf4cb84f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Group scores merged successfully. File saved at: /content/drive/My Drive/Capstone Project/SAS Star Data/Source Code/Analysis/PtExp Scenario Analysis Output/All_Group_Scores.csv\n","Summary scores calculated successfully. File saved at: /content/drive/My Drive/Capstone Project/SAS Star Data/Source Code/Analysis/PtExp Scenario Analysis Output/Summary_Scores.csv\n","Report indicator and grouping saved to /content/drive/My Drive/Capstone Project/SAS Star Data/Source Code/Analysis/PtExp Scenario Analysis Output/Report_Indicator.csv\n","K-means clustering and star ratings completed. Results saved to /content/drive/My Drive/Capstone Project/SAS Star Data/Source Code/Analysis/PtExp Scenario Analysis Output/Star_Ratings.csv.\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.cluster import KMeans\n","from scipy.stats import zscore\n","\n","##### Merge Files ######################################################################################################################\n","\n","# Paths to group score CSV files\n","STEP_1_OUT_PATH = '/content/drive/My Drive/Capstone Project/SAS Star Data/Source Code/output/Step 1 Out'\n","OUTPUT_PATH = '/content/drive/My Drive/Capstone Project/SAS Star Data/Source Code/Analysis/PtExp Scenario Analysis Output'\n","\n","# Load group scores\n","mortality_scores = pd.read_csv(f\"{STEP_1_OUT_PATH}/Outcome_mortality.csv\").rename(columns={\"grp_score\": \"Std_Outcomes_Mortality_score\"})\n","readmission_scores = pd.read_csv(f\"{STEP_1_OUT_PATH}/Outcome_readmission.csv\").rename(columns={\"grp_score\": \"Std_Outcomes_Readmission_score\"})\n","safety_scores = pd.read_csv(f\"{STEP_1_OUT_PATH}/Outcome_safety.csv\").rename(columns={\"grp_score\": \"Std_Outcomes_Safety_score\"})\n","pt_exp_scores = pd.read_csv(f\"{STEP_1_OUT_PATH}/PtExp.csv\").rename(columns={\"grp_score\": \"Std_PatientExp_score\"})\n","process_scores = pd.read_csv(f\"{STEP_1_OUT_PATH}/Process.csv\").rename(columns={\"grp_score\": \"Std_Process_score\"})\n","\n","# Merge all group scores into one DataFrame\n","all_scores = mortality_scores.merge(\n","    readmission_scores[['PROVIDER_ID', 'Std_Outcomes_Readmission_score']],\n","    on='PROVIDER_ID', how='outer'\n",").merge(\n","    safety_scores[['PROVIDER_ID', 'Std_Outcomes_Safety_score']],\n","    on='PROVIDER_ID', how='outer'\n",").merge(\n","    pt_exp_scores[['PROVIDER_ID', 'Std_PatientExp_score']],\n","    on='PROVIDER_ID', how='outer'\n",").merge(\n","    process_scores[['PROVIDER_ID', 'Std_Process_score']],\n","    on='PROVIDER_ID', how='outer'\n",")\n","\n","# Save the merged data to the output directory\n","merged_output_path = f\"{OUTPUT_PATH}/All_Group_Scores.csv\"\n","all_scores.to_csv(merged_output_path, index=False)\n","\n","print(f\"Group scores merged successfully. File saved at: {merged_output_path}\")\n","\n","##### Summary Score ######################################################################################################################\n","\n","# Load the merged data\n","merged_file_path = f\"{OUTPUT_PATH}/All_Group_Scores.csv\"\n","data = pd.read_csv(merged_file_path)\n","\n","# Fixed standard weights with redistributed patient experience weight\n","weights = {\n","    \"Std_PatientExp_score\": 0.11,  # Halved weight for patient experience\n","    \"Std_Outcomes_Readmission_score\": 0.245,  # Redistributed weights\n","    \"Std_Outcomes_Mortality_score\": 0.245,\n","    \"Std_Outcomes_Safety_score\": 0.245,\n","    \"Std_Process_score\": 0.155\n","}\n","\n","# Add weights to DataFrame\n","for group, weight in weights.items():\n","    data[f\"std_weight_{group}\"] = weight\n","\n","# Indicator for missing group scores\n","for group in weights.keys():\n","    data[f\"I_{group}\"] = data[group].isna().astype(int)\n","\n","# Redistribute weights\n","for group in weights.keys():\n","    redistribution_factor = 1 - sum(data[f\"I_{col}\"] * weights[col] for col in weights.keys())\n","    data[f\"weight_{group}\"] = np.where(\n","        data[f\"I_{group}\"] == 1,\n","        np.nan,  # Keep missing if group is missing\n","        data[f\"std_weight_{group}\"] / redistribution_factor\n","    )\n","\n","# Calculate weighted scores\n","for group in weights.keys():\n","    data[f\"sum_weight_ave_{group}\"] = data[f\"weight_{group}\"] * data[group]\n","\n","# Calculate the final summary score\n","weighted_cols = [f\"sum_weight_ave_{group}\" for group in weights.keys()]\n","data[\"summary_score\"] = data[weighted_cols].sum(axis=1)\n","\n","# Save the resulting summary scores to a new CSV file\n","summary_output_path = f\"{OUTPUT_PATH}/Summary_Scores.csv\"\n","data.to_csv(summary_output_path, index=False)\n","\n","print(f\"Summary scores calculated successfully. File saved at: {summary_output_path}\")\n","\n","##### Reporting >3 Measures #############################################################################################################\n","\n","MEASURE_ANALYSIS = \"/content/drive/My Drive/Capstone Project/SAS Star Data/Source Code/output/Step 0 Out/Std_data_2024Jul_analysis.csv\"\n","REPORT_OUTPUT_PATH = f\"{OUTPUT_PATH}/Report_Indicator.csv\"\n","\n","# Load the standardized data\n","data = pd.read_csv(MEASURE_ANALYSIS)\n","\n","# Define groups with correct column names\n","measure_OM = ['std_MORT_30_AMI', 'std_MORT_30_CABG', 'std_MORT_30_COPD', 'std_MORT_30_HF',\n","              'std_MORT_30_PN', 'std_MORT_30_STK', 'std_PSI_4_SURG_COMP']\n","measure_OS = ['std_COMP_HIP_KNEE', 'std_HAI_1', 'std_HAI_2', 'std_HAI_3', 'std_HAI_4',\n","              'std_HAI_5', 'std_HAI_6', 'std_PSI_90_SAFETY']\n","measure_OR = ['std_EDAC_30_AMI', 'std_EDAC_30_HF', 'std_EDAC_30_PN', 'std_OP_32',\n","              'std_READM_30_CABG', 'std_READM_30_COPD', 'std_READM_30_HIP_KNEE',\n","              'std_READM_30_HOSP_WIDE', 'std_OP_35_ADM', 'std_OP_35_ED', 'std_OP_36']\n","measure_PtExp = ['std_H_COMP_1_STAR_RATING', 'std_H_COMP_2_STAR_RATING', 'std_H_COMP_3_STAR_RATING',\n","                 'std_H_COMP_5_STAR_RATING', 'std_H_COMP_6_STAR_RATING', 'std_H_COMP_7_STAR_RATING',\n","                 'std_H_GLOB_STAR_RATING', 'std_H_INDI_STAR_RATING']\n","measure_Process = ['std_HCP_COVID_19', 'std_IMM_3', 'std_OP_10', 'std_OP_13', 'std_OP_18B',\n","                   'std_OP_22', 'std_OP_23', 'std_OP_29', 'std_OP_3B', 'std_OP_8', 'std_PC_01', 'std_SEP_1']\n","\n","# Count measures for each group\n","data['Outcomes_Mortality_cnt'] = data[measure_OM].notnull().sum(axis=1)\n","data['Outcomes_Safety_cnt'] = data[measure_OS].notnull().sum(axis=1)\n","data['Outcomes_Readmission_cnt'] = data[measure_OR].notnull().sum(axis=1)\n","data['Patient_Experience_cnt'] = data[measure_PtExp].notnull().sum(axis=1)\n","data['Process_cnt'] = data[measure_Process].notnull().sum(axis=1)\n","\n","# Calculate Total Measure Group Count\n","data['Total_measure_group_cnt'] = (\n","    (data['Outcomes_Mortality_cnt'] >= 3).astype(int) +\n","    (data['Outcomes_Safety_cnt'] >= 3).astype(int) +\n","    (data['Outcomes_Readmission_cnt'] >= 3).astype(int) +\n","    (data['Patient_Experience_cnt'] >= 3).astype(int) +\n","    (data['Process_cnt'] >= 3).astype(int)\n",")\n","\n","# Calculate MortSafe Group Count\n","data['MortSafe_Group_cnt'] = (\n","    (data['Outcomes_Mortality_cnt'] >= 3).astype(int) +\n","    (data['Outcomes_Safety_cnt'] >= 3).astype(int)\n",")\n","\n","# Determine Reporting Indicator\n","data['report_indicator'] = (\n","    (data['MortSafe_Group_cnt'] >= 1) & (data['Total_measure_group_cnt'] >= 3)\n",").astype(int)\n","\n","# Assign Peer Grouping\n","def assign_peer_group(row):\n","    if row['Total_measure_group_cnt'] == 3:\n","        return '1) # of groups=3'\n","    elif row['Total_measure_group_cnt'] == 4:\n","        return '2) # of groups=4'\n","    elif row['Total_measure_group_cnt'] == 5:\n","        return '3) # of groups=5'\n","    return None\n","\n","data['cnt_grp'] = data.apply(assign_peer_group, axis=1)\n","\n","# Save the Report Indicator Output\n","data[['PROVIDER_ID', 'report_indicator', 'Patient_Experience_cnt', 'Outcomes_Readmission_cnt',\n","      'Outcomes_Mortality_cnt', 'Outcomes_Safety_cnt', 'Process_cnt',\n","      'Total_measure_group_cnt', 'MortSafe_Group_cnt', 'cnt_grp']].to_csv(REPORT_OUTPUT_PATH, index=False)\n","\n","print(f\"Report indicator and grouping saved to {REPORT_OUTPUT_PATH}\")\n","\n","##### K-means Clustering ##############################################################################################################\n","\n","# Load the report macro results\n","data = pd.read_csv(REPORT_OUTPUT_PATH)\n","summary_scores = pd.read_csv(summary_output_path)\n","\n","# Merge `summary_score` into `data`\n","if 'summary_score' not in data.columns:\n","    data = data.merge(summary_scores[['PROVIDER_ID', 'summary_score']], on='PROVIDER_ID', how='left')\n","\n","# Function to perform K-means clustering\n","def kmeans_clustering(data, peer_group, n_clusters=5):\n","    group_data = data[(data['cnt_grp'] == peer_group) & (data['report_indicator'] == 1)].copy()\n","    if group_data.empty:\n","        return pd.DataFrame()\n","    quintiles = np.percentile(group_data['summary_score'], [20, 40, 60, 80])\n","    quintile_medians = [\n","        group_data[group_data['summary_score'] <= quintiles[0]]['summary_score'].median(),\n","        group_data[(group_data['summary_score'] > quintiles[0]) & (group_data['summary_score'] <= quintiles[1])]['summary_score'].median(),\n","        group_data[(group_data['summary_score'] > quintiles[1]) & (group_data['summary_score'] <= quintiles[2])]['summary_score'].median(),\n","        group_data[(group_data['summary_score'] > quintiles[2]) & (group_data['summary_score'] <= quintiles[3])]['summary_score'].median(),\n","        group_data[group_data['summary_score'] > quintiles[3]]['summary_score'].median()\n","    ]\n","    initial_centers = np.array([m for m in quintile_medians if not np.isnan(m)]).reshape(-1, 1)\n","    kmeans_phase1 = KMeans(n_clusters=n_clusters, init=initial_centers, n_init=1, max_iter=1000, random_state=42)\n","    group_data['cluster'] = kmeans_phase1.fit_predict(group_data[['summary_score']])\n","    group_data = group_data[np.abs(zscore(group_data['summary_score'])) < 3]\n","    kmeans_phase2 = KMeans(n_clusters=n_clusters, init=kmeans_phase1.cluster_centers_, n_init=1, max_iter=1000, random_state=42)\n","    group_data['cluster'] = kmeans_phase2.fit_predict(group_data[['summary_score']])\n","    cluster_means = group_data.groupby('cluster')['summary_score'].mean().sort_values()\n","    cluster_to_star = {cluster: star for star, cluster in enumerate(cluster_means.index, start=1)}\n","    group_data['star'] = group_data['cluster'].map(cluster_to_star)\n","    return group_data[['PROVIDER_ID', 'star', 'cnt_grp']]\n","\n","# Apply K-means to each peer group\n","peer_groups = data['cnt_grp'].unique()\n","all_clusters = []\n","for peer_group in peer_groups:\n","    clustered_data = kmeans_clustering(data, peer_group)\n","    if not clustered_data.empty:\n","        all_clusters.append(clustered_data)\n","\n","# Combine results for all peer groups\n","all_clusters_df = pd.concat(all_clusters, ignore_index=True)\n","data = data.merge(all_clusters_df, on=['PROVIDER_ID', 'cnt_grp'], how='left')\n","data['star'] = np.where(data['report_indicator'] == 0, \"N/A\", data['star'])\n","\n","# Save final results\n","final_output_path = f\"{OUTPUT_PATH}/Star_Ratings.csv\"\n","data.to_csv(final_output_path, index=False)\n","print(f\"K-means clustering and star ratings completed. Results saved to {final_output_path}.\")\n"]},{"cell_type":"markdown","source":["# Filter for riverside"],"metadata":{"id":"Dw-9cri-MwcS"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Path to the Star Ratings file\n","STAR_RATINGS_FILE = \"/content/drive/My Drive/Capstone Project/SAS Star Data/Source Code/Analysis/PtExp Scenario Analysis Output/Star_Ratings.csv\"\n","\n","# List of Riverside CCNs (ensure these are strings)\n","riverside_ccns = [\"490037\", \"490052\", \"490130\", \"490143\"]\n","\n","# Read the star ratings file\n","star_ratings = pd.read_csv(STAR_RATINGS_FILE)\n","\n","# Ensure PROVIDER_ID is treated as a string\n","star_ratings['PROVIDER_ID'] = star_ratings['PROVIDER_ID'].astype(str)\n","\n","# Filter for the Riverside hospitals\n","riverside_star_ratings = star_ratings[star_ratings['PROVIDER_ID'].isin(riverside_ccns)]\n","\n","# Display the filtered results\n","if not riverside_star_ratings.empty:\n","    print(\"Star Ratings for Riverside Hospitals:\")\n","    print(riverside_star_ratings)\n","else:\n","    print(\"No matching CCNs found for Riverside hospitals in the dataset.\")\n","\n","# Save the filtered results to a new CSV file\n","output_path = \"/content/drive/My Drive/Capstone Project/SAS Star Data/Source Code/Analysis/PtExp Scenario Analysis Output/Riverside_Star_Ratings.csv\"\n","riverside_star_ratings.to_csv(output_path, index=False)\n","\n","print(f\"Filtered star ratings saved to: {output_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kd-ZSotSMvhQ","executionInfo":{"status":"ok","timestamp":1733022750928,"user_tz":300,"elapsed":181,"user":{"displayName":"Ben Uehlinger","userId":"08830289083401511848"}},"outputId":"f019c7dc-d24e-4ea8-aac1-d74a344a95dc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Star Ratings for Riverside Hospitals:\n","     PROVIDER_ID  report_indicator  Patient_Experience_cnt  \\\n","4199      490037                 1                       8   \n","4210      490052                 1                       8   \n","4249      490130                 1                       8   \n","4253      490143                 1                       8   \n","\n","      Outcomes_Readmission_cnt  Outcomes_Mortality_cnt  Outcomes_Safety_cnt  \\\n","4199                         8                       5                    2   \n","4210                        10                       7                    7   \n","4249                         7                       5                    3   \n","4253                         7                       5                    3   \n","\n","      Process_cnt  Total_measure_group_cnt  MortSafe_Group_cnt  \\\n","4199            9                        4                   1   \n","4210           11                        5                   2   \n","4249            9                        5                   2   \n","4253            7                        5                   2   \n","\n","               cnt_grp  summary_score  star  \n","4199  2) # of groups=4       0.004129   3.0  \n","4210  3) # of groups=5      -0.307380   2.0  \n","4249  3) # of groups=5       0.002541   3.0  \n","4253  3) # of groups=5       0.264866   4.0  \n","Filtered star ratings saved to: /content/drive/My Drive/Capstone Project/SAS Star Data/Source Code/Analysis/PtExp Scenario Analysis Output/Riverside_Star_Ratings.csv\n"]}]}]}